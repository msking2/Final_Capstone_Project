{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c313d989-74ee-4243-96fb-1cf596b3475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Import SKLearn Compose Modules\n",
    "from sklearn.compose import (\n",
    "    make_column_selector,\n",
    "    make_column_transformer,\n",
    "    ColumnTransformer,\n",
    "    TransformedTargetRegressor\n",
    ")\n",
    "\n",
    "# Import SKLearn Preprocessing Modules\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures,\n",
    "    LabelEncoder\n",
    ")\n",
    "\n",
    "# Import SKLearn Linear Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\n",
    "\n",
    "# Import SKLearn Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Import SKLearn Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import SKLearn Model Selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Import SKLearn Metrics\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "# Import SKLearn KNN Models\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "# Import SKLearn SVM Model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import SKLearn Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import SKLearn Ensemble Models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    VotingClassifier, \n",
    "    RandomForestRegressor, \n",
    "    GradientBoostingRegressor, \n",
    "    ExtraTreesRegressor\n",
    ")\n",
    "\n",
    "# Import SKLearn Dummy\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bd699-b8ef-47d3-955a-872b7b624d19",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c61cf6-8502-432b-bc86-2adcb6ec6e11",
   "metadata": {},
   "source": [
    "Power information has not been centrally collected and managed and therefore many products have no data.  The goal is to develop a model to estimate typical power for our products where data is unavailable: There will be 3 parts to this project:\n",
    "    1. Using unsupervised learning, group like products together based on BOM information and other categorical data.\n",
    "    2. Based on the groupings and available data, use a supervised learning module to estimate product weight, as itâ€™s related to product power.\n",
    "    3. Predict the weight for products with no data. Use this completed data set to create a new supervised learning module to estimate the power for products with no power data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b64a40e0-b3f8-4f3a-8974-f36b9ac78941",
   "metadata": {},
   "source": [
    "### Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027f03f-2142-4139-b7db-828763cd11d2",
   "metadata": {},
   "source": [
    "The energy my companies products consume is its largest source of greenhouse gas emissions. By better estimating the power from the products with no data we can more accurately estimate the annual total emissions from the sale of our products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f3ddb-dd3e-454a-ad48-b9856689f79c",
   "metadata": {},
   "source": [
    "### Load in initial file with labeled and unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc69a1b-135d-44b1-8b8b-8092c5c50c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source: internal systems\n",
    "\n",
    "df = pd.read_csv('20250714_MASTER_DATA.csv')\n",
    "df1 = df\n",
    "\n",
    "# Manually labeled data that was incorrectly classified\n",
    "re = pd.read_csv('20250714_reinforcement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fbdf95-ff0a-433a-98ce-9d1ef9dd451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine re and df1 data where re superceeds df1 data\n",
    "required_cols = {'TOP_PID', 'MECH_COMP', 'MOD_COMP'}\n",
    "missing_cols = required_cols - set(re.columns)\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"The following required columns are missing in 're': {missing_cols}\")\n",
    "\n",
    "# Step 1: Merge re into df on TOP_PID\n",
    "merged = df1.merge(\n",
    "    re[['TOP_PID', 'MECH_COMP', 'MOD_COMP']],\n",
    "    on='TOP_PID',\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# Step 2: Replace only if new value is not null\n",
    "if 'MECH_COMP_new' in merged.columns:\n",
    "    df1['MECH_COMP'] = merged['MECH_COMP_new'].combine_first(df1['MECH_COMP'])\n",
    "\n",
    "if 'MOD_COMP_new' in merged.columns:\n",
    "    df1['MOD_COMP'] = merged['MOD_COMP_new'].combine_first(df1['MOD_COMP'])\n",
    "\n",
    "# Step 3: Drop temporary columns if they exist\n",
    "df1.drop(columns=['MECH_COMP_new', 'MOD_COMP_new'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268304e9-d674-432c-823e-d52f93bf2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93449 entries, 0 to 93448\n",
      "Data columns (total 86 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   TOP_PID                                        93449 non-null  object \n",
      " 1   USER_ITEM_TYPE                                 93449 non-null  object \n",
      " 2   BK_PRODUCT_TYPE_ID                             93449 non-null  object \n",
      " 3   MECH_COMP                                      65787 non-null  object \n",
      " 4   MOD_COMP                                       65787 non-null  object \n",
      " 5   TYP_PWR_W                                      6161 non-null   float64\n",
      " 6   PROD_PWR_W                                     32569 non-null  float64\n",
      " 7   POWER_TYPE                                     32569 non-null  object \n",
      " 8   PACKAGING_WEIGHT_KG                            35416 non-null  float64\n",
      " 9   NET_WEIGHT_KG                                  35416 non-null  float64\n",
      " 10  01-ASIC Module                                 93449 non-null  int64  \n",
      " 11  05-Optical Passive                             93449 non-null  int64  \n",
      " 12  06-Audio Equipment                             93449 non-null  int64  \n",
      " 13  07-RF Equipment                                93449 non-null  int64  \n",
      " 14  08-ASIC                                        93449 non-null  int64  \n",
      " 15  10-Optical Active                              93449 non-null  int64  \n",
      " 16  11-Capacitor                                   93449 non-null  int64  \n",
      " 17  12-Resistor                                    93449 non-null  int64  \n",
      " 18  13-Diode                                       93449 non-null  int64  \n",
      " 19  15-Communication                               93449 non-null  int64  \n",
      " 20  15-Linear                                      93449 non-null  int64  \n",
      " 21  15-Logic                                       93449 non-null  int64  \n",
      " 22  15-Memory                                      93449 non-null  int64  \n",
      " 23  15-Microprocessor                              93449 non-null  int64  \n",
      " 24  15-Multimedia                                  93449 non-null  int64  \n",
      " 25  15-OptoElectronic                              93449 non-null  int64  \n",
      " 26  15-RF                                          93449 non-null  int64  \n",
      " 27  15-Timing                                      93449 non-null  int64  \n",
      " 28  15-Transducer                                  93449 non-null  int64  \n",
      " 29  16-Programmable Logic                          93449 non-null  int64  \n",
      " 30  16-Programmable Memory                         93449 non-null  int64  \n",
      " 31  17-Programmed Device                           93449 non-null  int64  \n",
      " 32  18-Delay Line                                  93449 non-null  int64  \n",
      " 33  19-Crystal-Oscillator-SAW Oscillator           93449 non-null  int64  \n",
      " 34  20-Transistor                                  93449 non-null  int64  \n",
      " 35  21-Filter-Circuit Protection                   93449 non-null  int64  \n",
      " 36  22-Switch                                      93449 non-null  int64  \n",
      " 37  23-Relay                                       93449 non-null  int64  \n",
      " 38  24-Transformer-Inductor-Toroid                 93449 non-null  int64  \n",
      " 39  25-LED                                         93449 non-null  int64  \n",
      " 40  26-Socket                                      93449 non-null  int64  \n",
      " 41  28-Printed Circuit Board                       93449 non-null  int64  \n",
      " 42  29_27-Connector-Header-Terminal                93449 non-null  int64  \n",
      " 43  30-Telecommunications Module                   93449 non-null  int64  \n",
      " 44  300-Liquid Cooling Assy                        93449 non-null  int64  \n",
      " 45  301-Custom Quick Disconnect Coupling           93449 non-null  int64  \n",
      " 46  302-Quick Disconnect Coupling                  93449 non-null  int64  \n",
      " 47  303-Tubing                                     93449 non-null  int64  \n",
      " 48  304-Pump                                       93449 non-null  int64  \n",
      " 49  305-Coolant                                    93449 non-null  int64  \n",
      " 50  31-Raw Wire-Raw Cable                          93449 non-null  int64  \n",
      " 51  32-Wire Lug                                    93449 non-null  int64  \n",
      " 52  33-Fan-Blower                                  93449 non-null  int64  \n",
      " 53  33-Fan-Blower.1                                93449 non-null  int64  \n",
      " 54  34-Off the Shelf Power Supply                  93449 non-null  int64  \n",
      " 55  341-Custom Power Supply                        93449 non-null  int64  \n",
      " 56  35-Battery                                     93449 non-null  int64  \n",
      " 57  36-Ferrite Array                               93449 non-null  int64  \n",
      " 58  37-Jack-Power Cord                             93449 non-null  int64  \n",
      " 59  39-Optical Connector-Cable                     93449 non-null  int64  \n",
      " 60  43-Video Equipment - Camera-Lens-Image Sensor  93449 non-null  int64  \n",
      " 61  43-Video Equipment - Display                   93449 non-null  int64  \n",
      " 62  48-Screw                                       93449 non-null  int64  \n",
      " 63  49-Nut-Washer                                  93449 non-null  int64  \n",
      " 64  50-Standoff-Spacer                             93449 non-null  int64  \n",
      " 65  501-Packaging - Foam                           93449 non-null  int64  \n",
      " 66  502-Packaging - Bag-Envelope                   93449 non-null  int64  \n",
      " 67  503-Packaging - Wood                           93449 non-null  int64  \n",
      " 68  504-Packaging - OEM Data                       93449 non-null  int64  \n",
      " 69  51-General Hardware-Gasket                     93449 non-null  int64  \n",
      " 70  51-Heatsink                                    93449 non-null  int64  \n",
      " 71  52-Clip-Clamp                                  93449 non-null  int64  \n",
      " 72  53-Accessory Kit                               93449 non-null  int64  \n",
      " 73  55-Packaging - Corrugated Component            93449 non-null  int64  \n",
      " 74  58-Disk Drive                                  93449 non-null  int64  \n",
      " 75  66-Pluggable Optic                             93449 non-null  int64  \n",
      " 76  68-Final Assembl                               93449 non-null  int64  \n",
      " 77  69-Mechanical Kit                              93449 non-null  int64  \n",
      " 78  700-Custom Fabricated - Metal-Plastic          93449 non-null  int64  \n",
      " 79  700-Custom Heatsink                            93449 non-null  int64  \n",
      " 80  72-Cable Assembly-Wiring Harness               93449 non-null  int64  \n",
      " 81  73-Printed Circuit Assembly                    93449 non-null  int64  \n",
      " 82  74-ODM or OEM Assembly                         93449 non-null  int64  \n",
      " 83  800-Assembly-Sub Assembly                      93449 non-null  int64  \n",
      " 84  800-Heatsink Assembly                          93449 non-null  int64  \n",
      " 85  84-Packaging Assembly                          93449 non-null  int64  \n",
      "dtypes: float64(4), int64(76), object(6)\n",
      "memory usage: 61.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70402d5-518f-4432-a187-84cf773ecf75",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Choicelist and default value do not have a common dtype: The DType <class 'numpy.dtypes._PyFloatDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes._PyFloatDType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     51\u001b[0m conditions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     52\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMECH_COMP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOD_COMP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTYP_PWR_W\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     55\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROD_PWR_W\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m ]\n\u001b[1;32m     57\u001b[0m choices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmech\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 59\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mselect(conditions, choices, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Drop unneeded columns that were combined above\u001b[39;00m\n\u001b[1;32m     64\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m300-Liquid Cooling Assy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m301-Custom Quick Disconnect Coupling\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m302-Quick Disconnect Coupling\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     65\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m303-Tubing\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m304-Pump\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m305-Coolant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01-ASIC Module\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m08-ASIC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Logic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Communication\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Linear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Microprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     66\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Multimedia\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-OptoElectronic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-RF\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Timing\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15-Transducer\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16-Programmable Logic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16-Programmable Memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNET_WEIGHT_KG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     77\u001b[0m               ], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:871\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(condlist, choicelist, default)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    870\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChoicelist and default value do not have a common dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;66;03m# Convert conditions to arrays and broadcast conditions and choices\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# as the shape is needed for the result. Doing it separately optimizes\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# for example when all choices are scalars.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m condlist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_arrays(\u001b[38;5;241m*\u001b[39mcondlist)\n",
      "\u001b[0;31mTypeError\u001b[0m: Choicelist and default value do not have a common dtype: The DType <class 'numpy.dtypes._PyFloatDType'> could not be promoted by <class 'numpy.dtypes.StrDType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes._PyFloatDType'>)"
     ]
    }
   ],
   "source": [
    "# Define column groups for clarity and reuse\n",
    "ic_cols = [\n",
    "    '01-ASIC Module', '08-ASIC', '15-Logic','15-Communication', '15-Linear', '15-Memory',\n",
    "    '15-Microprocessor', '15-Multimedia', '15-OptoElectronic', '15-RF', '15-Timing',\n",
    "    '15-Transducer', '16-Programmable Logic', '16-Programmable Memory', '17-Programmed Device'\n",
    "]\n",
    "\n",
    "elec_cols = [\n",
    "    '11-Capacitor', '12-Resistor', '13-Diode', '18-Delay Line', '19-Crystal-Oscillator-SAW Oscillator',\n",
    "    '20-Transistor', '21-Filter-Circuit Protection', '22-Switch', '23-Relay',\n",
    "    '24-Transformer-Inductor-Toroid', '25-LED', '26-Socket'\n",
    "]\n",
    "\n",
    "pack_cols = [\n",
    "    '501-Packaging - Foam', '502-Packaging - Bag-Envelope', '503-Packaging - Wood',\n",
    "    '504-Packaging - OEM Data', '55-Packaging - Corrugated Component'\n",
    "]\n",
    "\n",
    "mech_cols = [\n",
    "    '48-Screw', '49-Nut-Washer', '50-Standoff-Spacer', '51-General Hardware-Gasket', '51-Heatsink',\n",
    "    '52-Clip-Clamp', '700-Custom Fabricated - Metal-Plastic', '700-Custom Heatsink', '32-Wire Lug'\n",
    "]\n",
    "\n",
    "psu_cols = [\n",
    "    '34-Off the Shelf Power Supply', '341-Custom Power Supply', '36-Ferrite Array'\n",
    "]\n",
    "\n",
    "cable_cols = [\n",
    "    '31-Raw Wire-Raw Cable', '37-Jack-Power Cord', '72-Cable Assembly-Wiring Harness'\n",
    "]\n",
    "\n",
    "kit_cols = [\n",
    "    '69-Mechanical Kit', '53-Accessory Kit'\n",
    "]\n",
    "\n",
    "optical_cols = [\n",
    "    '05-Optical Passive', '10-Optical Active', '66-Pluggable Optic'\n",
    "]\n",
    "\n",
    "# Create category totals\n",
    "df1['IC'] = df[ic_cols].sum(axis=1)\n",
    "df1['elec'] = df[elec_cols].sum(axis=1)\n",
    "df1['pack'] = df[pack_cols].sum(axis=1)\n",
    "df1['mech'] = df[mech_cols].sum(axis=1)\n",
    "df1['psu'] = df[psu_cols].sum(axis=1)\n",
    "df1['cable'] = df[cable_cols].sum(axis=1)\n",
    "df1['kit'] = df[kit_cols].sum(axis=1)\n",
    "df1['optical'] = df[optical_cols].sum(axis=1)\n",
    "\n",
    "# Assign 'type' using priority logic\n",
    "conditions = [\n",
    "    df['MECH_COMP'] == 'Y',\n",
    "    df['MOD_COMP'] == 'Y',\n",
    "    df['TYP_PWR_W'] > 0,\n",
    "    df['PROD_PWR_W'] > 0\n",
    "]\n",
    "choices = ['mech', 'mod', 'pwr','pwr']\n",
    "\n",
    "df1['type'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "\n",
    "# Drop unneeded columns that were combined above\n",
    "\n",
    "df1 = df1.drop(['300-Liquid Cooling Assy','301-Custom Quick Disconnect Coupling','302-Quick Disconnect Coupling',\n",
    "               '303-Tubing','304-Pump','305-Coolant', '01-ASIC Module', '08-ASIC', '15-Logic','15-Communication','15-Linear','15-Memory','15-Microprocessor',\n",
    "               '15-Multimedia','15-OptoElectronic','15-RF','15-Timing','15-Transducer','16-Programmable Logic','16-Programmable Memory',\n",
    "               '17-Programmed Device','11-Capacitor','12-Resistor','13-Diode','18-Delay Line','19-Crystal-Oscillator-SAW Oscillator',\n",
    "                 '20-Transistor','21-Filter-Circuit Protection','22-Switch','23-Relay',\n",
    "                 '24-Transformer-Inductor-Toroid','25-LED','26-Socket','501-Packaging - Foam','502-Packaging - Bag-Envelope','503-Packaging - Wood',\n",
    "                  '504-Packaging - OEM Data','55-Packaging - Corrugated Component','48-Screw','49-Nut-Washer','50-Standoff-Spacer','51-General Hardware-Gasket','51-Heatsink',\n",
    "                  '52-Clip-Clamp','700-Custom Fabricated - Metal-Plastic','700-Custom Heatsink','73-Printed Circuit Assembly','800-Assembly-Sub Assembly',\n",
    "               '800-Heatsink Assembly','84-Packaging Assembly','68-Final Assembl','33-Fan-Blower.1','32-Wire Lug',\n",
    "               '34-Off the Shelf Power Supply','341-Custom Power Supply','36-Ferrite Array','31-Raw Wire-Raw Cable',\n",
    "               '37-Jack-Power Cord','72-Cable Assembly-Wiring Harness','69-Mechanical Kit','53-Accessory Kit',\n",
    "               '05-Optical Passive','10-Optical Active','66-Pluggable Optic','MECH_COMP','MOD_COMP','TYP_PWR_W', 'PROD_PWR_W','POWER_TYPE','PACKAGING_WEIGHT_KG'\n",
    "                ,'NET_WEIGHT_KG'\n",
    "              ], axis = 1)\n",
    "\n",
    "# Summerize total components and create new column\n",
    "\n",
    "df1['total_comp'] = df1[[\n",
    "    '06-Audio Equipment', '07-RF Equipment', '28-Printed Circuit Board',\n",
    "    '29_27-Connector-Header-Terminal', '30-Telecommunications Module', '33-Fan-Blower',\n",
    "    '35-Battery', '39-Optical Connector-Cable', '43-Video Equipment - Camera-Lens-Image Sensor',\n",
    "    '43-Video Equipment - Display', '58-Disk Drive', '74-ODM or OEM Assembly',\n",
    "    'IC', 'elec', 'pack', 'mech', 'psu', 'cable', 'kit', 'optical'\n",
    "]].sum(axis=1)\n",
    "\n",
    "# Drop items that have > 1 74- CC and < 200 components\n",
    "\n",
    "df2 = df1[\n",
    "    (df1['74-ODM or OEM Assembly'] == 0) |\n",
    "    ((df1['74-ODM or OEM Assembly'] > 1) & (df1['total_comp'] > 200)) \n",
    "]\n",
    "\n",
    "# Change 'nan' into NaN\n",
    "\n",
    "df2['type'] = df2['type'].replace(['nan', 'None'], np.nan)\n",
    "# Drop items that have 0 total compoents\n",
    "\n",
    "df2 = df2.query('total_comp > 0')\n",
    "\n",
    "# Split file into labeled (lab) and unlabeled (unlab) data. This is based on type notation.\n",
    "\n",
    "lab = df2[df2['type'].notna()]   # rows where 'type' is NOT null\n",
    "unlab = df2[df2['type'].isna()]  # rows where 'type' IS null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6806af1-1cdc-406c-b6db-84fc589740a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each unique value in the target variable\n",
    "target_quantity = lab['type'].value_counts(dropna=False)\n",
    "\n",
    "# Create a bar chart using seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=target_quantity.index, y=target_quantity.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Unique Values in Type')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec6734-a9d6-4425-9a59-ab09a7ee8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing data in labeled data. There is no missing data, all data is either 0 or has a value.\n",
    "\n",
    "# Count missing per column\n",
    "missing_count = lab.isnull().sum()\n",
    "\n",
    "# % missing per column\n",
    "missing_percent = 100 * lab.isnull().sum() / len(df)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_count,\n",
    "    'Missing %': missing_percent\n",
    "}).sort_values(by=\"Missing %\", ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f500a-caf0-4861-990a-fea18e3ec506",
   "metadata": {},
   "source": [
    "### Check how balanced data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84140cf8-7b72-4c4f-816c-8a639b3cedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['total_comp', 'IC', 'elec', 'mech']\n",
    "\n",
    "# Create 4 subplots (2 rows Ã— 2 columns)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for ax, col in zip(axes.flat, cols):\n",
    "    sns.kdeplot(lab[col], fill=True, linewidth=2, alpha=0.4, ax=ax)\n",
    "    ax.set_title(f\"KDE of {col}\")\n",
    "    ax.set_xlabel(\"Values\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "plt.suptitle(\"KDE Plots for Multiple Features\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be2c96-e3e5-49e0-9821-1c1642a561b6",
   "metadata": {},
   "source": [
    "I selected a few sample features to check to see how skewed the data was. Based on the analysis, there are a lot of products that have smaller values and a longer tail of products with higher values, but fewer of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06578d84-dd5b-43eb-a8ec-491bcb20e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a log transofrmation to reduce skewness\n",
    "\n",
    "lab3 = pd.DataFrame()\n",
    "lab3['IC_log'] = np.log1p(lab['IC'])\n",
    "lab3['elec_log'] = np.log1p(lab['elec'])\n",
    "lab3['mech_log'] = np.log1p(lab['mech'])\n",
    "lab3['total_comp_log'] = np.log1p(lab['total_comp'])\n",
    "\n",
    "cols = ['total_comp_log', 'IC_log', 'elec_log', 'mech_log']\n",
    "\n",
    "# Create 4 subplots (2x2 grid)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for ax, col in zip(axes.flat, cols):\n",
    "    sns.kdeplot(lab3[col], fill=True, linewidth=2, alpha=0.4, ax=ax)\n",
    "    ax.set_title(f\"KDE of {col}\")\n",
    "    ax.set_xlabel(\"Values\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "plt.suptitle(\"KDE Plots for Log-Transformed Features\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac7d16-e0c1-454a-a289-0c45b725ca99",
   "metadata": {},
   "source": [
    "I corrected for the skewness by using a log function which created a more balanced data set which should help with optimizing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906929a5-8a6d-4f53-abe5-3d0996c4c57e",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68ccc8-d0cb-4b4a-ba9e-3acea4580286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features X and target y\n",
    "X = lab.drop(['type' , 'TOP_PID'], axis=1)\n",
    "y = lab['type']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Identify  new categorical and numerical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Split the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00b00c-9628-46d5-a8f1-b027ee888e72",
   "metadata": {},
   "source": [
    "### Check baseline using dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20562d37-95ea-4bb8-a333-a507cf738c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "print(\"Baseline (Most Frequent Class):\")\n",
    "print(classification_report(y_test, y_pred_dummy, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca7441-a64e-492f-839e-004d9395df79",
   "metadata": {},
   "source": [
    "Mod is the majority class (2951/6554). If Mod was choosen everytime the accuracy would be 45%, therefore any model should perform better than the 45% accuracy and 62% F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8aa878-122a-4712-a47d-dcc02acec22b",
   "metadata": {},
   "source": [
    "### Determine Best Classification Model and Hyperparameters for Type Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9db3c-5019-4d89-947f-6f94926a769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build ColumnTransformer for preprocessing\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(drop='first',handle_unknown='ignore'), categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dictionary of models and hyperparameter grids for tuning with GridSearchCV\n",
    "\n",
    "models = {\n",
    "    'knn': (KNeighborsClassifier(), {\n",
    "        'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'knn__weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'logisticregression': (LogisticRegression(max_iter=1000, solver='saga'), {\n",
    "        'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'logisticregression__penalty': ['l1', 'l2']\n",
    "    }),\n",
    "    'svc': (SVC(), {\n",
    "        'svc__C': [0.1, 1, 10],\n",
    "        'svc__kernel': ['linear', 'rbf']\n",
    "    }),\n",
    "    'decisiontreeclassifier': (DecisionTreeClassifier(), {\n",
    "        'decisiontreeclassifier__max_depth': [5, 10, 15],\n",
    "        'decisiontreeclassifier__min_samples_split': [2, 5, 10],\n",
    "        'decisiontreeclassifier__min_samples_leaf': [1, 2, 4],\n",
    "        'decisiontreeclassifier__criterion': ['gini', 'entropy']\n",
    "    }),  # ðŸ‘ˆ add this comma\n",
    "    'randomforest': (RandomForestClassifier(), {\n",
    "        'randomforest__n_estimators': [100, 200],\n",
    "        'randomforest__max_depth': [5, 10, 20],\n",
    "        'randomforest__min_samples_split': [2, 5],\n",
    "        'randomforest__min_samples_leaf': [1, 2]\n",
    "    }),\n",
    "    'gradientboosting': (GradientBoostingClassifier(), {\n",
    "        'gradientboosting__n_estimators': [100, 200],\n",
    "        'gradientboosting__learning_rate': [0.01, 0.1],\n",
    "        'gradientboosting__max_depth': [3, 5]\n",
    "    })\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16a9fe-02a7-4954-b231-b39516e074f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train + Evaluate models\n",
    "# ---------------------------\n",
    "results = []\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        (name, model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, n_jobs=-1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    fit_time = (time.time() - start_time) / len(grid_search.cv_results_['mean_fit_time'])\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    train_score = best_model.score(X_train, y_train)\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results.append([name, train_score, test_score, fit_time, precision, recall, f1, best_model])\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(f'Confusion Matrix: {name}')\n",
    "    plt.show()\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=['model', 'train score', 'test score', 'average fit time', 'precision', 'recall', 'f1', 'best_estimator']\n",
    ").set_index('model')\n",
    "\n",
    "print(\"\\nModel Performance:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Rank models and select top 3\n",
    "# ---------------------------\n",
    "top_models = results_df.sort_values(by=['f1', 'test score'], ascending=False)\n",
    "best_3 = top_models.head(3)\n",
    "print(\"\\nTop 3 Models:\\n\")\n",
    "print(best_3)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Build VotingClassifier ensemble\n",
    "# ---------------------------\n",
    "best_estimators = [(name, best_3.loc[name, 'best_estimator']) for name in best_3.index]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_score = voting_clf.score(X_test, y_test)\n",
    "print(f\"\\nVoting Ensemble Test Accuracy: {voting_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99762c8d-3782-44fb-a7b8-272a734b6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify best model, hyperparameters and score\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", round(grid_search.best_score_*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36451a9-0f76-4303-8bb1-d40aa9f90e81",
   "metadata": {},
   "source": [
    "The best model selected was Gradient Boosting, using a learning rate of 0.1, a maximum depth of 5, and 200 estimators. The model achieved a train score of 96.5% and a test score of 93.9%, with an average fit time of approximately 9.2 seconds. In this use case, precision is the most important metric, as it represents the ratio of TP/(TP + FP), meaning we want to minimize false positives. Gradient Boosting not only provides strong precision but also performs consistently across recall and F1-score, making it the best overall model for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252b505-254e-44aa-af09-f1a16052ada2",
   "metadata": {},
   "source": [
    "### Using Best Model Predict Product Type for Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3f426-b475-4a2e-9b6b-2466fc9dfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Apply the best model to predict on the unlabelled data\n",
    "unlab1 = unlab.drop(['type'], axis=1)\n",
    "\n",
    "# Use the best model for predictions\n",
    "preds = best_model.predict(unlab1)\n",
    "\n",
    "# Add predictions and original 'TOP_PID' to the DataFrame\n",
    "unlab1['Predicted'] = preds\n",
    "unlab1['TOP_PID'] = unlab['TOP_PID']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf12661-6578-4272-81c8-001c37b4fbe0",
   "metadata": {},
   "source": [
    "### Create One File To predict Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c992b-1d9a-4314-ab78-f7a7d1aa0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange unlab1 to combine with lab\n",
    "\n",
    "unlab2 = unlab1.rename(columns = {'Predicted' : 'type'})\n",
    "\n",
    "\n",
    "unlab2 = unlab2[['TOP_PID'] + [col for col in unlab2.columns if col != 'TOP_PID']]\n",
    "#unlab2 = unlab2.set_index('TOP_PID')\n",
    "\n",
    "# Get list of all columns\n",
    "cols = unlab2.columns.tolist()\n",
    "\n",
    "# Remove 'total_comp' from its current position\n",
    "cols.remove('total_comp')\n",
    "\n",
    "# Insert it at position 23 (which is the 24th column)\n",
    "cols.insert(24, 'total_comp')\n",
    "\n",
    "# Reorder the DataFrame\n",
    "unlab2 = unlab2[cols]\n",
    "\n",
    "# Assign a numerical value to the different types to match the formatting on lab data\n",
    "unlab2['type'] = unlab2['type'].map({0: 'mech', 1: 'mod', 2: 'pwr'})\n",
    "\n",
    "# Add labeled and unlabeled data together\n",
    "combined = pd.concat([lab, unlab2], ignore_index=False)\n",
    "\n",
    "# Bring weight back into calculation\n",
    "\n",
    "combined1 = combined.set_index('TOP_PID')\n",
    "df1 = df.set_index('TOP_PID')\n",
    "\n",
    "\n",
    "wght = combined1.merge(\n",
    "    df1[['NET_WEIGHT_KG']],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convert type data back to numerical values\n",
    "wght['type'] = wght['type'].map({'mech' : 0, 'mod' : 1, 'pwr' : 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73b284-c611-43ab-88f0-81212a2767ab",
   "metadata": {},
   "source": [
    "#### Determine Best Model and Hyperparameters to Predict Weight Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9ad99-0663-4037-9445-f013d7c7992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into labeled and unlabeled\n",
    "\n",
    "wghtlab = wght[wght['NET_WEIGHT_KG'].notna()]   # rows where 'type' is NOT null\n",
    "wghtunlab = wght[wght['NET_WEIGHT_KG'].isna()]  # rows where 'type' IS null\n",
    "\n",
    "wghtlab = wghtlab[wghtlab['NET_WEIGHT_KG'] < 20].copy()\n",
    "\n",
    "# Split data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(wghtlab.drop(['NET_WEIGHT_KG'], axis = 1), \n",
    "                                                    wghtlab['NET_WEIGHT_KG'], random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e93caa-35a0-4172-936a-43d6ffc2ffa1",
   "metadata": {},
   "source": [
    "Based on initial testing, outliers were preventing the model from having a RMSE below 44, which was no better then just predicting a value using the mean and standard deviation. It was determined that limiting the labeled weight data to products with less then 20 kg weight created a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fada2b1-789c-4c05-af2d-ad9483aecd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of product weight\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(wghtlab['NET_WEIGHT_KG'], bins=200, kde=True)\n",
    "plt.title(\"Distribution of NET_WEIGHT_KG\")\n",
    "plt.xlabel(\"Weight (kg)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf4fec-78c6-468d-8a7a-ceb1dd5d2129",
   "metadata": {},
   "source": [
    "### Create Model to Predict Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff92613-20af-4633-8211-c915510e017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "X_num = X_train.select_dtypes(include='number')\n",
    "\n",
    "# Compute correlation with target\n",
    "corrs = X_num.corrwith(y_train)\n",
    "\n",
    "# Sort by absolute value\n",
    "corrs_sorted = corrs.abs().sort_values(ascending=False)\n",
    "print(corrs_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f7e29-dc76-46ef-b85e-7f96e7751cce",
   "metadata": {},
   "source": [
    "After checking for correlation, it was determined to only use features that had a correlation > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f999e-69be-4ba9-b1a7-35287bcd9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model pipeline and test models to determine model that will produce the lowest RMSE\n",
    "\n",
    "# 1. Select top features\n",
    "top_features = ['mech', '29_27-Connector-Header-Terminal', '35-Battery', \n",
    "                'IC', 'total_comp', 'pack', 'psu', 'elec']\n",
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]\n",
    "\n",
    "# 2. Pipeline (scaling + regressor placeholder)\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge())   \n",
    "])\n",
    "\n",
    "# 3. Wrap with TransformedTargetRegressor (log-transform)\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=pipe,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "# 4. GridSearchCV parameter grid (Ridge, Lasso, KNN)\n",
    "param_grid = [\n",
    "    {\n",
    "        'regressor__regressor': [Ridge(), Lasso()],\n",
    "        'regressor__regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    {\n",
    "        'regressor__regressor': [KNeighborsRegressor()],\n",
    "        'regressor__regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'regressor__regressor__weights': ['uniform', 'distance']\n",
    "    }\n",
    "]\n",
    "\n",
    "# 5. Run GridSearchCV\n",
    "gridcv = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gridcv.fit(X_train_top, y_train)\n",
    "\n",
    "# 6. Predict and evaluate\n",
    "y_pred = gridcv.predict(X_test_top)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Best parameters:\", gridcv.best_params_)\n",
    "print(\"Best estimator:\", gridcv.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4691ee-1d60-442a-bded-74b18438b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DummyRegressor (baseline model)\n",
    "dummy = DummyRegressor(strategy=\"mean\")  # predicts mean of training set\n",
    "dummy.fit(X_train_top, y_train)\n",
    "\n",
    "# Predict with dummy\n",
    "y_dummy_pred = dummy.predict(X_test_top)\n",
    "\n",
    "# Evaluate dummy\n",
    "dummy_rmse = np.sqrt(mean_squared_error(y_test, y_dummy_pred))\n",
    "print(\"Dummy RMSE (mean baseline):\", dummy_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb503d-9bf0-4fae-9da3-667e1368ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean, standard deviation and R^2 of y_test to compare against RMSE value\n",
    "\n",
    "print(\"y_train mean value:\", y_train.mean())\n",
    "print(\"y_train standard deviation:\", y_train.std())\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af8cec-cdbc-4915-b1ff-9344ae57b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare actual vs predicted data\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # 45Â° line\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed7424-85ed-42d5-9eff-52ba259bc34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare residuals vs actuals\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.scatterplot(x=y_test, y=residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46025f-dba4-45f3-b645-d1c61c3135f9",
   "metadata": {},
   "source": [
    "The best model identified was a KNeighbors Regressor with n_neighbors = 3 and weights = distance. The RMSE was 2.03 which was suppier to just picking the mean and using the standard deviation of the dataset which would have been 5.69 and 4.78 accordingly. The R^2 value was 0.818, which is close to 1 which is considered perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a6657-d370-433c-aec1-ba75bebe20c1",
   "metadata": {},
   "source": [
    "### Predict missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203341a2-8fe6-4302-a5f3-eda895f40bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict missing data and join back with original data\n",
    "wghtunlab1 = wghtunlab.drop(['NET_WEIGHT_KG'], axis=1)\n",
    "\n",
    "# Select top features\n",
    "top_features = ['mech', '29_27-Connector-Header-Terminal', '35-Battery', 'IC', 'total_comp', 'pack', 'psu', 'elec']\n",
    "wghtunlab2 = wghtunlab1[top_features]\n",
    "\n",
    "\n",
    "# Use the best model from GridSearchCV to predict\n",
    "y_pred = gridcv.best_estimator_.predict(wghtunlab2)\n",
    "\n",
    "# Add predictions and TOP_PID to the DataFrame\n",
    "wghtunlab2 = wghtunlab2.copy()  # ensure safe assignment\n",
    "wghtunlab2['Predicted'] = y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18a4a9-80d9-4b11-aa3d-20fd463e8d5c",
   "metadata": {},
   "source": [
    "### Create one file to predict power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c0c7f-8c10-490c-bba4-8f1a22e99b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneed features\n",
    "\n",
    "top_features = ['mech', '29_27-Connector-Header-Terminal', '35-Battery', 'IC', 'total_comp', 'pack', 'psu', 'elec', 'NET_WEIGHT_KG', 'type']\n",
    "wghtlab1 = wghtlab[top_features]\n",
    "\n",
    "wghtunlab3 = wghtunlab2.rename(columns = {'Predicted' : 'NET_WEIGHT_KG'})\n",
    "wghtunlab3['type'] = wghtunlab['type']\n",
    "\n",
    "# Add labeled and unlabeled data together\n",
    "\n",
    "combined = pd.concat([wghtlab1, wghtunlab3], ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb004e-7149-4765-af05-b063088a26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring power back into calculation\n",
    "\n",
    "combined.index = combined.index.astype(str)\n",
    "df1.index = df1.index.astype(str)\n",
    "\n",
    "df1 = df.set_index('TOP_PID')\n",
    "\n",
    "pwr = combined.merge(\n",
    "    df1[['PROD_PWR_W', 'POWER_TYPE']],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "pwr1 = pwr[pwr['type'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59594d33-f59f-4234-8a7b-ffec1507ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into labeled and unlabeled\n",
    "\n",
    "pwrlab = pwr1[pwr1['POWER_TYPE'] == 'Product Power']   # rows where 'type' is NOT null\n",
    "pwrunlab = pwr1[pwr1['POWER_TYPE'].isin(['Product Family Power','BU Power','Average Power']) | (pwr['POWER_TYPE'].isna())]  # rows where 'type' IS null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ec2a0-e515-40bb-a068-8a0ca77a73af",
   "metadata": {},
   "source": [
    "### Create Model and Hyperparameters to Predict Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a1634-160f-4d75-b3a4-990a89337499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pwrlab.drop(['PROD_PWR_W','POWER_TYPE', 'type'], axis=1), \n",
    "    pwrlab['PROD_PWR_W'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline: scaler + regressor placeholder\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge()) \n",
    "])\n",
    "\n",
    "# Wrap with log-transform to prevent negative predictions\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=pipe,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "# GridSearchCV parameters for Ridge, Lasso, KNN\n",
    "param_grid = [\n",
    "    # Ridge Regression\n",
    "    {\n",
    "        'regressor__regressor': [Ridge()],\n",
    "        'regressor__regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    # Lasso Regression\n",
    "    {\n",
    "        'regressor__regressor': [Lasso(max_iter=50000)],\n",
    "        'regressor__regressor__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    },\n",
    "    # KNN Regressor\n",
    "    {\n",
    "        'regressor__regressor': [KNeighborsRegressor()],\n",
    "        'regressor__regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'regressor__regressor__weights': ['uniform', 'distance']\n",
    "    }\n",
    "]\n",
    "\n",
    "gridcvpwr = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gridcvpwr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = gridcvpwr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Best parameters:\", gridcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57852a-5b6a-46cd-92f8-3ea29b70065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy regressor to set baseline\n",
    "\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy = dummy.predict(X_test)\n",
    "rmse_dummy = np.sqrt(mean_squared_error(y_test, y_dummy))\n",
    "\n",
    "print(\"RMSE (dummy baseline):\", rmse_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33e729-74c0-44e6-bbbd-11c5c37dacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean, standard deviation and R^2 of y_test to compare against RMSE value\n",
    "\n",
    "print(\"y_train mean value:\", y_train.mean())\n",
    "print(\"y_train standard deviation:\", y_train.std())\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc14f0-4e26-4cf3-b349-096536cda7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted value vs actual\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # 45Â° line\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357689f1-2b80-4811-bfa2-a86c0c713cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals vs actuals\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.scatterplot(x=y_test, y=residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee940e-cac5-42b0-8f7a-00419ce7a685",
   "metadata": {},
   "source": [
    "The best model identified was a KNeighbors Regressor with n_neighbors = 3 and weights = distance. The RMSE was 116.50 which was supperier to just picking the mean and using the standard deviation of the dataset which would have been 129.12 and 242.71 accordingly. The R^2 value was 0.767, which is close to 1 which is considered perfect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50a175-9f67-4e26-845d-e084de4b8ebf",
   "metadata": {},
   "source": [
    "### Predict missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63a593-6e56-45c3-8170-44d0dbb371bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict missing values for unlabeled data\n",
    "\n",
    "pwrunlab1 = pwrunlab.drop(['PROD_PWR_W', 'POWER_TYPE', 'type'], axis = 1)\n",
    "\n",
    "best_model = gridcvpwr.best_estimator_\n",
    "\n",
    "preds = best_model.predict(pwrunlab1)\n",
    "\n",
    "# Add missing data to file for review\n",
    "\n",
    "pwrunlab2 = pwrunlab1\n",
    "pwrunlab2['Predicted'] = preds\n",
    "pwrunlab2['PROD_PWR_W'] = pwrunlab['PROD_PWR_W']\n",
    "\n",
    "# Print to file\n",
    "\n",
    "pwrunlab2.to_csv('pwrun.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
